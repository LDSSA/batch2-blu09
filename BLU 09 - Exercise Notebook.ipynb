{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "69eee7b96f53e9fd4f417b5f6000e540",
     "grade": false,
     "grade_id": "cell-2c9c6fdf3e87a0f7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fedb9b1dc32efc4ef58bf069c5e06b5f",
     "grade": false,
     "grade_id": "cell-9690996ec7c3c08f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "docs_ = []\n",
    "with open('datasets/sample_data.json') as fp:\n",
    "    for line in fp:\n",
    "        entry = json.loads(line)\n",
    "        docs_.append(entry['body'])\n",
    "\n",
    "print('Loaded {} documents'.format(len(docs_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "385b5935e70838363ef500b6caae2b0c",
     "grade": false,
     "grade_id": "cell-bbc68a16f01c06dc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable=['parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c025e9eff048706844a826686127f2d0",
     "grade": false,
     "grade_id": "cell-c40b542a2405da8b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "docs = list(nlp.pipe(docs_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f4631a5cd7ec07821d7b0201a398cdc7",
     "grade": false,
     "grade_id": "cell-3964f5278d3e2e45",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q1 - Feature Extraction with spacy I\n",
    "\n",
    "You are working with text and it is important to known **how much data can the text provide you with**. In these exercises you will approach techniques that extract information from text data as well as to use them to improve your machine learning classifier.\n",
    "To do this, we are going to start working with our sample dataset from Reddit where you'll be asked to extract some bits of knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b9e1d7725d7380b8275fd134fee77d7",
     "grade": false,
     "grade_id": "cell-3dea605d980c76c1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In this first problem you are given a list of four names and your task is to find which one is not present in the given set of documents. Take advantage of spacy's `Matcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f0dc01722e4008ef52498dbe3b9b7e4b",
     "grade": false,
     "grade_id": "cell-55ecaaf064135066",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "names = ['Tom', 'John', 'Teresa', 'Christian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d29f80e3c7e73e8c95d62f13405d1aaf",
     "grade": false,
     "grade_id": "cell-e1c582f5472593cf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#matcher = Matcher(...)\n",
    "#\n",
    "#for name in names:\n",
    "#    pattern = [...]\n",
    "#    matcher.add(...)\n",
    "#\n",
    "#for doc in docs:\n",
    "#    matches = ...\n",
    "#    for ...:\n",
    "#        span = ...\n",
    "#        print(span)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8a31308571cf1bbc5e3e87210c140e85",
     "grade": false,
     "grade_id": "cell-99bc3d8492ee9709",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "So, which of the names is not in the corpus of documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "982bf3d7b220837d65209f04d72cb768",
     "grade": false,
     "grade_id": "cell-e388ba211cc5dfa9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#answer = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a46320e54a1126557a100223d242777b",
     "grade": true,
     "grade_id": "cell-8c4c03bc54acfdc0",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "eh = '81f3bf42a93cf18dece9321ac5c93313126eb5ca92164d74643e4cbf60ecde9c'\n",
    "assert hashlib.sha256(str(answer).encode()).hexdigest() == eh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1cfa593bd9f1f4e0dac671fa7cb477b0",
     "grade": false,
     "grade_id": "cell-90610064b252d533",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q2 - Feature extraction with spacy II\n",
    "\n",
    "The second problem is fairly similar, but in this case you'll have to count the number of ocurrences that spacy interprets as being URLs. Looking at the following figure should help you choose the pattern to use now.\n",
    "\n",
    "![](media/token_attributes.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d6ef3eb9d9343d59d3e145b36a566276",
     "grade": false,
     "grade_id": "cell-1e7783e89b853ce6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#matcher = Matcher(...)\n",
    "#\n",
    "#pattern = [...]\n",
    "#matcher.add(...)\n",
    "#\n",
    "#count = ...\n",
    "#for doc in docs:\n",
    "#    matches = ...\n",
    "#    count += ...\n",
    "        \n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8adf9da60b83a78fb5f734f7a371261d",
     "grade": true,
     "grade_id": "cell-790c430e04cb0f1e",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "eh = '2abaca4911e68fa9bfbf3482ee797fd5b9045b841fdff7253557c5fe15de6477'\n",
    "assert hashlib.sha256(str(count).encode()).hexdigest() == eh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bdcc61c81e2a6606a3d8a9af831506b3",
     "grade": false,
     "grade_id": "cell-880531b38c9b67b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q3 - Extracting Part of Speech features\n",
    "\n",
    "Now you are going to check how reliable the vanilla part of speech tagging from spacy is. To do that, first, match all the adjectives and then look at the five most common.\n",
    "\n",
    "To help you, here's the list of PoS available in spacy:\n",
    "\n",
    "![](media/pos_helper.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "86b32d4739cb93358b13c0fd0fadb9da",
     "grade": false,
     "grade_id": "cell-64683287d0596aeb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#matcher = ...\n",
    "#pattern = [...]\n",
    "#matcher.add(...)\n",
    "#\n",
    "#adjs = list()\n",
    "#\n",
    "#for doc in docs:\n",
    "#    matches = ...\n",
    "#    for ...:\n",
    "#        span = ...\n",
    "#        adjs.append(str(span).lower())\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "722772dd8257ce31b2f8d913a6c481c7",
     "grade": false,
     "grade_id": "cell-c36ea3d7d3327e66",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(adjs).most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ced961563facde588892e4ed55270159",
     "grade": false,
     "grade_id": "cell-7510a80e7d6d1fe7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "So, does it look like the most common adjectives are indeed adjectives?\n",
    "\n",
    "- [ ] Yes\n",
    "- [ ] No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d1b664ff0e0ca9a3205481e44dd49681",
     "grade": false,
     "grade_id": "cell-bc6563456b9153a5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#answer = \"Yes\" or \"No\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9b12e67a88ed67ed7bd4981cc080770c",
     "grade": true,
     "grade_id": "cell-c7b15b3c21fe74f5",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "eh = '1ea442a134b2a184bd5d40104401f2a37fbc09ccf3f4bc9da161c6099be3691d'\n",
    "assert hashlib.sha256(str(answer).encode()).hexdigest() == eh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3f9c8a8e1f14f66edfa4b9482ba6a5ff",
     "grade": false,
     "grade_id": "cell-45e34f159eafa6a7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q4 - Extracting \"complex\" patterns\n",
    "\n",
    "How many people are going to somewhere productive in these documents? (Count instances of sentences with the structure verb with lemma go, followed by an adposition and one of the places listed).\n",
    "\n",
    "Note: Note that this is a very simple heuristic and that a setup like this is only reasonable for a problem in which you are getting familiar with spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4009616bce7b599b546805f3ea8531b3",
     "grade": false,
     "grade_id": "cell-68823353c4240178",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "places = ['School', 'College', 'Library']\n",
    "\n",
    "#matcher = ...\n",
    "#\n",
    "#for place in places:\n",
    "#    pattern = [..., ..., ...]\n",
    "#    matcher.add(...)\n",
    "#\n",
    "#count = ...\n",
    "#    \n",
    "#for doc in docs:\n",
    "#    matches = ...\n",
    "#    count += ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5a5bc325260eb9d483d9a405d75bc6d0",
     "grade": true,
     "grade_id": "cell-bc7be7e8fca147d1",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "eh = '4b227777d4dd1fc61c6f884f48641d02b4d121d3fd328cb08b5531fcacdabf8a'\n",
    "assert hashlib.sha256(str(count).encode()).hexdigest() == eh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7bf2b3f0fc27de4c615f42761dd2f1ab",
     "grade": false,
     "grade_id": "cell-a0a2a5c45b3c130c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q5 - Adding Extra Features\n",
    "\n",
    "You are given the task to build a better spam classifier. One possible factor that may help is to know the number of adjectives in each sms, as the number of verbs used and the length of the messages. \n",
    "\n",
    "Add extra fields to your dataframe with the count for the number of adjectives (ADJ) and verbs (VERB) Spacy recognized for each sms, as well with the length of the message (number of characters).\n",
    "\n",
    "How many adjectives and verbs do we have in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ebcf5543f09e8dcf6f4485f346ee89b9",
     "grade": false,
     "grade_id": "cell-124957b8f2212188",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/spam.csv', encoding='latin1')\n",
    "df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1,inplace=True)\n",
    "df.rename(columns={\"v1\":\"label\", \"v2\":\"message\"},inplace=True)\n",
    "df = df[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5e5d8b6a011d8937022473426fb1271e",
     "grade": false,
     "grade_id": "cell-bab0e5a3f8f8cbc7",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Hint: you can iterate over the tokens in Spacy doc to know each PoS tag for each token\n",
    "# for doc in nlp.pipe(df['message']):\n",
    "#    for token in doc:\n",
    "#        print(token.pos_)\n",
    "\n",
    "#n_adj = []\n",
    "#n_verbs = []\n",
    "#len_message = []\n",
    "#\n",
    "#for doc in nlp.pipe(df['message']):\n",
    "#    n_adj.append(...)\n",
    "#    n_verbs.append(...)\n",
    "#    len_message.append(...)\n",
    "#    \n",
    "#df['n_adj'] = ...\n",
    "#df['n_verbs'] = ...\n",
    "#df['len_message'] = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d9e6ca339aa2ef6184e9b9bc075a8ce",
     "grade": true,
     "grade_id": "cell-03dbc9fa2ea23663",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "total_adjs = sum(n_adj)\n",
    "total_verbs = sum(n_verbs)\n",
    "assert np.allclose(total_adjs, 3863, 20)\n",
    "assert np.allclose(total_verbs, 10696, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7fbc3d3ca2bb59528d2cbcb00ed40b32",
     "grade": false,
     "grade_id": "cell-923d795a48aa24c6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Q6 - Feature Unions\n",
    "\n",
    "Now we have these features, can we build a classifier using them? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "01407bbabee83e6e08066a16ff4f08a8",
     "grade": false,
     "grade_id": "cell-9c8ff5d97624ac9b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "class TextSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on text columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self.key]\n",
    "    \n",
    "class NumberSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Transformer to select a single column from the data frame to perform additional transformations on\n",
    "    Use on numeric columns in the data\n",
    "    \"\"\"\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[[self.key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "380bfc1de08f6988e5861229f18d70ec",
     "grade": false,
     "grade_id": "cell-7084694ab285eb01",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(feats, train_data, test_data):\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('features',feats),\n",
    "        ('classifier', RandomForestClassifier(random_state = 42)),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(train_data, train_data.label)\n",
    "\n",
    "    preds = pipeline.predict(test_data)\n",
    "    accuracy = np.mean(preds == test_data.label)\n",
    "    \n",
    "    print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "911f3e847140debe589784542a88991d",
     "grade": false,
     "grade_id": "cell-42ba44a8653efe95",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**a)** Use FeatureUnion to join text features extracted from a standard TfidfVectorizer with the numeric feature for the counts of adjectives in the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f8d36b0f0e9d836af62cc24a20d711da",
     "grade": false,
     "grade_id": "cell-0848e748dc61721f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#text = Pipeline(...)\n",
    "#adj =  Pipeline(...)\n",
    "#feats = FeatureUnion(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ec502667ef67eb529a9344d21a2be535",
     "grade": true,
     "grade_id": "cell-80971dd7f21ec905",
     "locked": true,
     "points": 3,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = get_accuracy(feats, train_data, test_data)\n",
    "assert np.allclose(accuracy, 0.9683, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f57717d9511f566206c3416f6781a15f",
     "grade": false,
     "grade_id": "cell-1f4ecd3a08b31cb9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**b)** Now add the number of verbs and see if the accuracy improves. You should notice that more features doesn't always mean better accuracy, as you may have seen previously during the LDSSA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8223c0b7cf55afdc40b03c595f63cd5a",
     "grade": false,
     "grade_id": "cell-0ef7216ae6023fdf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#text = Pipeline(...)\n",
    "#adj =  Pipeline(...)\n",
    "#verbs = Pipeline(...)\n",
    "#feats = FeatureUnion(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "11541e58ddd387367d50a549707d40e5",
     "grade": true,
     "grade_id": "cell-2726b142fbec4f14",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = get_accuracy(feats, train_data, test_data)\n",
    "assert np.allclose(accuracy, 0.9583, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5ee6734acc3c0cc235734b03db2c921f",
     "grade": false,
     "grade_id": "cell-b1aa91b08408579d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**c)** Finally make use of the length of the messages as well and see whether it improves the model accuracy or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "53e15511937a4686a0087bfcbd9654d9",
     "grade": false,
     "grade_id": "cell-f5770ba6afa04742",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#text = Pipeline(...)\n",
    "#adj =  Pipeline(...)\n",
    "#verbs = Pipeline(...)\n",
    "#len_message = Pipeline(...)\n",
    "#feats = FeatureUnion(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8e0ef45265b81032130e68d3fe22de49",
     "grade": true,
     "grade_id": "cell-8289104bef520ea7",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "accuracy = get_accuracy(feats, train_data, test_data)\n",
    "assert np.allclose(accuracy, 0.9717, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
